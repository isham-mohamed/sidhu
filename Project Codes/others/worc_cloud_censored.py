# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/154Beq9k1jegKnnvfQcpAEqQQ8Erd4QIH
"""

from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir('/content/drive/My Drive/Hate Speech Detection/Project Codes/')

import wordcloud
from wordcloud import WordCloud, STOPWORDS 
import matplotlib.pyplot as plt 
import pandas as pd 
import profanity_check
from profanity_check import predict, predict_prob


df = pd.read_csv(r"hate_clean.csv", encoding ="latin-1") 
data=df['tweet']
li=['e','i','o','u']
print(li)
  
comment_words = ' '
stopwords = set(STOPWORDS)
#print(data) 
  
# iterate through the csv file 
for val in data: 
      
    # typecaste each val to string 
    val = str(val) 
  
    # split the value 
    tokens = val.split()
      
    # Converts each token into lowercase 
    for i in range(len(tokens)): 
        tokens[i] = tokens[i].lower() 
    
    c = '*'
    for words in tokens:
      if predict_prob([words])>0.5:
        for ch in words:
          if ch in li:
            words=words.replace(ch,'0')
            words=str(words)
    comment_words = comment_words + words + ' '   
    for words in tokens:
        for ch in words:
            if ch in li:
                words=words.replace('0','*')     
wordcloud = WordCloud(width = 800, height = 800, 
            background_color ='white', 
            stopwords = stopwords, 
            min_font_size = 10).generate(comment_words) 
    
# plot the WordCloud image                        
plt.figure(figsize = (8, 8), facecolor = None) 
plt.imshow(wordcloud) 
plt.axis("off") 
plt.tight_layout(pad = 0) 
  
plt.show()

pip install profanity-check

